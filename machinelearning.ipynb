{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FatosGeração (ID empreendiemnto) > fatodadosmetereologicos (vento, precip, etc) > dimempreendimentos (tipogeração)\n",
    "\n",
    "#dim_empreendimentos -> id;NomEmpreendimento;SigUFPrincipal;SigTipoGeracao;NomFonteCombustivel\n",
    "#fato_dados_metereologicos -> id;Data;Hora UTC;precipTotalHorario;ventoVeloHoraria;tempAr;radGlobal;umidRelAr;id_regiao\n",
    "#fato_geracao -> id;DatGeracaoConjuntoDados;MdaPotenciaFiscalizadaKw;MdaPotenciaOutorgadaKw;Id_empreendimento\n",
    "#id;UF;latitude;longitude;altitude\n",
    "#Pegar empreendimento (id) > Pegar todos os dados meterologicos (preciptação, vento, temp...) > Pegar qual o TipoGeração na região\n",
    "\n",
    "dim_regiao = pd.read_csv(\n",
    "    \"data/dim_regiao.csv\",\n",
    "    delimiter=\";\",\n",
    "    encoding=\"UTF-8\")\n",
    "\n",
    "dim_empreendimentos = pd.read_csv(\n",
    "    \"data/dim_empreendimento.csv\",\n",
    "    delimiter=\";\",\n",
    "    encoding=\"UTF-8\")\n",
    "\n",
    "fato_dados_metereologicos = pd.read_csv(\n",
    "    \"data/fato_dados_meteorologicos.csv\",\n",
    "    delimiter=\";\",\n",
    "    encoding=\"UTF-8\")\n",
    "\n",
    "fato_geracao = pd.read_csv(\n",
    "    \"data/fato_geracao.csv\",\n",
    "    delimiter=\";\",\n",
    "    encoding=\"UTF-8\",\n",
    "    decimal=',')\n",
    "\n",
    "#sklearn.ensemble.HistGradientBoostingClassifier\n",
    "print(dim_regiao.head())\n",
    "print(dim_empreendimentos.head())\n",
    "print(fato_dados_metereologicos.head())\n",
    "print(fato_geracao.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim_empreendimentos['DscMuninicpios'].str.split('-')[0][0].strip()\n",
    "# melhora o nome da coluna para Municipios e filtra os nomes dos municipios para um padrão\n",
    "dim_empreendimentos['DscMuninicpios'] = dim_empreendimentos['DscMuninicpios'].apply(lambda x: unidecode(str(x).split('-')[0].strip().upper()))\n",
    "dim_empreendimentos['Municipios'] = dim_empreendimentos['DscMuninicpios']\n",
    "dim_empreendimentos.drop('DscMuninicpios', axis=1, inplace=True)\n",
    "\n",
    "dim_empreendimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dim_empreendimentos['Municipios'] = dim_empreendimentos['Municipios'].str.split('-', 1).str[0]\n",
    "# dim_empreendimentos['Municipios'] = dim_empreendimentos['Municipios'].str.split('-')[0][0].strip()\n",
    "# dim_empreendimentos['Municipios'] = dim_empreendimentos['Municipios'].str.upper()\n",
    "\n",
    "#Cidade, MediaPrecipTotalHorarioCidade, MediaVentoVeloHorariaCidade, MediaTempArCidade, ...., QuantidadeEnergiaEnergiaSolarGeradaPorCidade, QuantidadeEnergiaNuclearGeradaPorCidade, \n",
    "# QuantidadeEnergiaTermalGeradaPorCidade, .....\n",
    "\n",
    "\n",
    "empreendimentos_combinados = pd.merge(fato_geracao, dim_empreendimentos, left_on='Id_empreendimento', right_on='id')\n",
    "#dim_empreendimentos.head()\n",
    "\n",
    "#empreendimentos_combinados = empreendimentos_combinados.drop('DatGeracaoConjuntoDados', axis=1)\n",
    "#empreendimentos_combinados\n",
    "\n",
    "empreendimentos_combinados = empreendimentos_combinados.groupby(['Municipios','SigTipoGeracao'])['MdaPotenciaOutorgadaKw'].aggregate('sum').unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_regiao.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_combinados = pd.merge(fato_dados_metereologicos, dim_regiao[['id', 'UF','cidade']], left_on='id_regiao', right_on='id')\n",
    "\n",
    "#Tratando dados decimais para virarem tipo float\n",
    "#dados_combinados = pd.merge(fato_dados_metereologicos, dim_regiao, left_on='id_regiao', right_on='id')\n",
    "\n",
    "dados_combinados['precipTotalHorario'] = dados_combinados['precipTotalHorario'].astype(str)\n",
    "dados_combinados['precipTotalHorario'] = dados_combinados['precipTotalHorario'].str.replace(',', '.')\n",
    "dados_combinados['precipTotalHorario'] = dados_combinados['precipTotalHorario'].astype(float)\n",
    "\n",
    "dados_combinados['ventoVeloHoraria'] = dados_combinados['ventoVeloHoraria'].astype(str)\n",
    "dados_combinados['ventoVeloHoraria'] = dados_combinados['ventoVeloHoraria'].str.replace(',', '.')\n",
    "dados_combinados['ventoVeloHoraria'] = dados_combinados['ventoVeloHoraria'].astype(float)\n",
    "\n",
    "dados_combinados['tempAr'] = dados_combinados['tempAr'].astype(str)\n",
    "dados_combinados['tempAr'] = dados_combinados['tempAr'].str.replace(',', '.')\n",
    "dados_combinados['tempAr'] = dados_combinados['tempAr'].astype(float)\n",
    "\n",
    "dados_combinados['radGlobal'] = dados_combinados['radGlobal'].astype(str)\n",
    "dados_combinados['radGlobal'] = dados_combinados['radGlobal'].str.replace(',', '.')\n",
    "dados_combinados['radGlobal'] = dados_combinados['radGlobal'].astype(float)\n",
    "\n",
    "dados_combinados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_combinados.drop('id_y', axis=1, inplace=True)\n",
    "dados_combinados.drop('id_x', axis=1, inplace=True)\n",
    "\n",
    "dados_combinados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agrupar por cidade\n",
    "# fazer media de 'precipTotalHorario', 'ventoVeloHoraria', 'tempAr', 'radGlobal', 'umidRelAr'\n",
    "colunas_medias = ['precipTotalHorario', 'ventoVeloHoraria', 'tempAr', 'radGlobal', 'umidRelAr']\n",
    "dados_combinados = dados_combinados.groupby('cidade')[colunas_medias].mean().reset_index()\n",
    "dados_combinados.rename(columns={\n",
    "  'precipTotalHorario': 'media_preciptacao',\n",
    "  'ventoVeloHoraria': 'media_vento',\n",
    "  'tempAr': 'media_temperaturaAr',\n",
    "  'radGlobal': 'media_radiacao',\n",
    "  'umidRelAr': 'media_umidade'})\n",
    "#, inplace=True\n",
    "dados_combinados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(dados_combinados, empreendimentos_combinados, left_on='cidade', right_on='Municipios')\n",
    "df_final[['CGH', 'EOL' , 'PCH', 'UFV', 'UHE', 'UTE', 'UTN']] = df_final[['CGH', 'EOL' , 'PCH', 'UFV', 'UHE', 'UTE', 'UTN']].fillna(0)\n",
    "df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[168], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m model \u001b[39m=\u001b[39m MultiOutputClassifier(DecisionTreeRegressor())\n\u001b[0;32m     11\u001b[0m \u001b[39m# Treinar o modelo de árvore de decisão\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, np\u001b[39m.\u001b[39;49mravel(y_train))\n\u001b[0;32m     14\u001b[0m \u001b[39m# Fazer previsões utilizando o conjunto de teste\u001b[39;00m\n\u001b[0;32m     15\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\multioutput.py:450\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, Y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params):\n\u001b[0;32m    425\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \n\u001b[0;32m    427\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39m        Returns a fitted instance.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfit(X, Y, sample_weight, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m [estimator\u001b[39m.\u001b[39mclasses_ \u001b[39mfor\u001b[39;00m estimator \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_]\n\u001b[0;32m    452\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\multioutput.py:201\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    198\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(X\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_validation\u001b[39m\u001b[39m\"\u001b[39m, y\u001b[39m=\u001b[39my, multi_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    200\u001b[0m \u001b[39mif\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 201\u001b[0m     check_classification_targets(y)\n\u001b[0;32m    203\u001b[0m \u001b[39mif\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    204\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    205\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my must have at least two dimensions for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    206\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmulti-output regression but has only one.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    207\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\multiclass.py:218\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    210\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    211\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[0;32m    212\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    213\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    217\u001b[0m ]:\n\u001b[1;32m--> 218\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "# Separar as features (dados climáticos) e o target (tipo de geração de energia)\n",
    "features = df_final[['precipTotalHorario','ventoVeloHoraria','tempAr','radGlobal','umidRelAr']]  # substitua pelas colunas relevantes\n",
    "target = df_final[['CGH', 'EOL' , 'PCH', 'UFV', 'UHE', 'UTE', 'UTN']]\n",
    "\n",
    "# Dividir os dados em conjunto de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criar uma instância do modelo de árvore de decisão\n",
    "model = MultiOutputClassifier(DecisionTreeRegressor())\n",
    "\n",
    "# Treinar o modelo de árvore de decisão\n",
    "model.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Fazer previsões utilizando o conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliar a precisão do modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Erro quadrático médio (MSE):\", mse)\n",
    "print(\"Precisão do modelo:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_com_nan = df_final.columns[df_final.isnull().any()].tolist()\n",
    "print(\"Colunas com valores NaN:\")\n",
    "for coluna in colunas_com_nan:\n",
    "    print(coluna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar as features (dados climáticos) e os targets (tipos de geração de energia)\n",
    "features = df_final[['precipTotalHorario','ventoVeloHoraria','tempAr','radGlobal','umidRelAr']]\n",
    "target = df_final[['CGH', 'EOL' , 'PCH', 'UFV', 'UHE', 'UTE', 'UTN']]\n",
    "\n",
    "# Dividir os dados em conjunto de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criar uma instância do modelo de Classificador de Regressão Logística Multilabel\n",
    "model = MultiOutputClassifier(LogisticRegression())\n",
    "\n",
    "# Treinar o modelo de Classificador de Regressão Logística Multilabel\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões utilizando o conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliar o desempenho do modelo\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
